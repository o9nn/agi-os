(*
 * AGI-OS Integration Contracts - Z++ Formal Specification
 * 
 * This specification formalizes the contracts for external system
 * integration, including LLM APIs, storage backends, network protocols,
 * and inter-process communication interfaces.
 * 
 * Author: AGI-OS Development Team
 * Date: December 12, 2025
 * Version: 1.0
 *)

(* Import dependencies *)
include "data_model.zpp"
include "system_state.zpp"
include "operations.zpp"

(* ========================================================================
 * EXTERNAL LLM INTEGRATION
 * ======================================================================== *)

(*
 * LLM (Large Language Model) integration contracts
 * Supports multiple LLM backends: Mistral, Llama, GPT, etc.
 *)

[LLMProvider]
LLMProvider ::= Mistral | Llama | GPT | Claude | Local

schema LLMModel
  model_id: AtomName
  provider: LLMProvider
  model_name: AtomName
  context_length: ‚Ñï‚ÇÅ
  is_loaded: ùîπ
  quantization: AtomName    (* "Q4_K_M", "Q5_K_S", "F16", etc. *)
where
  model_id ‚â† ""
  model_name ‚â† ""
  (* Context length typically 2048 to 128K tokens *)
  context_length ‚â• 2048 ‚àß context_length ‚â§ 131072
  quantization ‚àà {"Q4_K_M", "Q5_K_S", "Q8_0", "F16", "F32"}
end

schema LLMPrompt
  prompt_id: ‚Ñï‚ÇÅ
  system_prompt: AtomName
  user_prompt: AtomName
  context_atoms: ‚Ñô AtomID    (* AtomSpace context *)
  max_tokens: ‚Ñï‚ÇÅ
  temperature: ‚Ñù
  top_p: Probability
where
  prompt_id > 0
  max_tokens > 0 ‚àß max_tokens ‚â§ 4096
  0.0 ‚â§ temperature ‚àß temperature ‚â§ 2.0
  0.0 < top_p ‚àß top_p ‚â§ 1.0
end

schema LLMResponse
  response_id: ‚Ñï‚ÇÅ
  prompt_id: ‚Ñï‚ÇÅ
  generated_text: AtomName
  tokens_used: ‚Ñï
  inference_time: ‚Ñï         (* Milliseconds *)
  finish_reason: AtomName   (* "stop", "length", "error" *)
where
  response_id > 0
  prompt_id > 0
  tokens_used ‚â• 0
  inference_time ‚â• 0
  finish_reason ‚àà {"stop", "length", "error", "cancelled"}
end

(*
 * InvokeLLM: Call external LLM service
 *)

schema InvokeLLM
  ŒûAtomSpaceState
  model: LLMModel
  prompt: LLMPrompt
  response!: LLMResponse
  success!: ùîπ
where
  (* Pre-conditions *)
  model.is_loaded
  prompt.context_atoms ‚äÜ dom atoms
  
  (* Serialize context atoms to text *)
  let context_text = serialize_atoms_to_text(
    {aid: prompt.context_atoms ‚Ä¢ atoms(aid)}
  ) in
  
  (* Construct full prompt *)
  let full_prompt = 
    prompt.system_prompt + "\n\n" +
    "Context:\n" + context_text + "\n\n" +
    "Query: " + prompt.user_prompt in
  
  (* Call LLM inference *)
  let (output_text, token_count, time_ms, reason) = 
    model.provider.inference(
      model.model_name,
      full_prompt,
      prompt.max_tokens,
      prompt.temperature,
      prompt.top_p
    ) in
  
  (* Construct response *)
  response! = LLMResponse {
    response_id = generate_response_id(),
    prompt_id = prompt.prompt_id,
    generated_text = output_text,
    tokens_used = token_count,
    inference_time = time_ms,
    finish_reason = reason
  } ‚àß
  
  success! = (reason ‚àà {"stop", "length"})
end

(*
 * ParseLLMOutput: Parse LLM output into AtomSpace
 *)

schema ParseLLMOutput
  ŒîAtomSpaceState
  response: LLMResponse
  suggestion_atoms!: ‚Ñô AtomID
where
  (* Extract structured suggestions from text *)
  let suggestions = extract_suggestions(response.generated_text) in
  
  (* Parse each suggestion into atoms *)
  suggestion_atoms! = {s: suggestions ‚Ä¢ 
    parse_suggestion_to_atoms(s, atomspace)
  }
end

(* ========================================================================
 * STORAGE BACKEND INTEGRATION
 * ======================================================================== *)

(*
 * RocksDB Backend Contract
 *)

schema RocksDBBackend
  extends StorageBackend
  db_path: AtomName
  cache_size: ‚Ñï‚ÇÅ             (* Cache size in MB *)
  write_buffer_size: ‚Ñï‚ÇÅ
  compression_enabled: ùîπ
where
  backend_type = RocksDB
  db_path ‚â† ""
  cache_size ‚â• 8 ‚àß cache_size ‚â§ 65536
  write_buffer_size ‚â• 4 ‚àß write_buffer_size ‚â§ 1024
end

schema RocksDBStore
  backend: RocksDBBackend
  atom: Atom
  success!: ùîπ
where
  backend.is_connected
  ¬¨backend.read_only
  
  (* Serialize atom to key-value *)
  let key = encode_atom_key(atom.atom_id) in
  let value = serialize_atom(atom) in
  
  (* Write to RocksDB *)
  success! = backend.db_handle.put(key, value)
end

schema RocksDBFetch
  backend: RocksDBBackend
  atom_id: AtomID
  atom!: Atom
  found!: ùîπ
where
  backend.is_connected
  
  (* Read from RocksDB *)
  let key = encode_atom_key(atom_id) in
  let (value, exists) = backend.db_handle.get(key) in
  
  found! = exists ‚àß
  (exists ‚üπ atom! = deserialize_atom(value))
end

(*
 * PostgreSQL Backend Contract
 *)

schema PostgreSQLBackend
  extends StorageBackend
  host: AtomName
  port: ‚Ñï‚ÇÅ
  database: AtomName
  username: AtomName
  password: AtomName
  pool_size: ‚Ñï‚ÇÅ
where
  backend_type = PostgreSQL
  host ‚â† ""
  port ‚àà 1..65535
  database ‚â† ""
  username ‚â† ""
  pool_size ‚â• 1 ‚àß pool_size ‚â§ 100
end

schema PostgreSQLStore
  backend: PostgreSQLBackend
  atoms: ‚Ñô Atom
  success!: ùîπ
where
  backend.is_connected
  ¬¨backend.read_only
  
  (* Begin transaction *)
  let tx = backend.begin_transaction() in
  
  (* Insert atoms *)
  ‚àÄ a: atoms ‚Ä¢
    let sql = generate_insert_sql(a) in
    tx.execute(sql)
  
  (* Commit transaction *)
  success! = tx.commit()
end

schema PostgreSQLQuery
  backend: PostgreSQLBackend
  sql_query: AtomName
  results!: ‚Ñô Atom
where
  backend.is_connected
  
  (* Execute query *)
  let rows = backend.execute_query(sql_query) in
  
  (* Parse results *)
  results! = {row: rows ‚Ä¢ parse_row_to_atom(row)}
end

(*
 * IPFS Backend Contract (Content-Addressed Storage)
 *)

schema IPFSBackend
  extends StorageBackend
  ipfs_node_url: AtomName
  gateway_url: AtomName
  pin_all: ùîπ              (* Pin all content permanently *)
where
  backend_type = IPFS
  ipfs_node_url ‚â† ""
  gateway_url ‚â† ""
end

schema IPFSStore
  backend: IPFSBackend
  atomspace_snapshot: AtomSpace
  content_hash!: AtomName
  success!: ùîπ
where
  backend.is_connected
  ¬¨backend.read_only
  
  (* Serialize entire atomspace *)
  let content = serialize_atomspace(atomspace_snapshot) in
  
  (* Add to IPFS *)
  let (hash, added) = backend.ipfs_api.add(content) in
  
  (* Pin if configured *)
  backend.pin_all ‚àß added ‚üπ
    backend.ipfs_api.pin(hash)
  
  content_hash! = hash ‚àß
  success! = added
end

schema IPFSFetch
  backend: IPFSBackend
  content_hash: AtomName
  atomspace!: AtomSpace
  success!: ùîπ
where
  backend.is_connected
  
  (* Fetch from IPFS *)
  let (content, fetched) = backend.ipfs_api.get(content_hash) in
  
  (* Deserialize atomspace *)
  fetched ‚üπ atomspace! = deserialize_atomspace(content)
  
  success! = fetched
end

(* ========================================================================
 * NETWORK PROTOCOL INTEGRATION
 * ======================================================================== *)

(*
 * Model Context Protocol (MCP) - Anthropic's standard
 *)

[MCPMessageType]
MCPMessageType ::= Request | Response | Notification | Error

schema MCPMessage
  message_id: ‚Ñï‚ÇÅ
  message_type: MCPMessageType
  method: AtomName
  params: ‚Ñô KeyValuePair
  timestamp: Timestamp
where
  message_id > 0
  method ‚â† "" ‚üπ message_type = Request
end

schema MCPRequest
  extends MCPMessage
  session_id: ‚Ñï‚ÇÅ
where
  message_type = Request
  method ‚àà {"get_atom", "add_atom", "execute_query", 
             "get_types", "pattern_match"}
end

schema MCPResponse
  extends MCPMessage
  request_id: ‚Ñï‚ÇÅ
  result: ‚Ñô KeyValuePair
  success: ùîπ
where
  message_type = Response
  request_id > 0
end

(*
 * HandleMCPRequest: Process MCP protocol request
 *)

schema HandleMCPRequest
  ŒûAtomSpaceState
  request: MCPRequest
  response!: MCPResponse
where
  (* Route to appropriate handler *)
  request.method = "get_atom" ‚üπ
    let atom_id_str = get_param(request.params, "atom_id") in
    let atom_id = parse_atom_id(atom_id_str) in
    atom_id ‚àà dom atoms ‚üπ
      response! = MCPResponse {
        message_id = generate_message_id(),
        message_type = Response,
        request_id = request.message_id,
        result = serialize_atom_to_kvp(atoms(atom_id)),
        success = true,
        method = "",
        params = ‚àÖ,
        timestamp = current_time
      }
  
  request.method = "execute_query" ‚üπ
    let pattern_str = get_param(request.params, "pattern") in
    let pattern = parse_pattern(pattern_str) in
    let solutions = execute_query(pattern, atoms) in
      response! = MCPResponse {
        message_id = generate_message_id(),
        message_type = Response,
        request_id = request.message_id,
        result = serialize_solutions_to_kvp(solutions),
        success = true,
        method = "",
        params = ‚àÖ,
        timestamp = current_time
      }
end

(*
 * RESTful HTTP API
 *)

[HTTPMethod]
HTTPMethod ::= GET | POST | PUT | DELETE | PATCH

[HTTPStatus]
HTTPStatus == 100..599

schema HTTPRequest
  request_id: ‚Ñï‚ÇÅ
  method: HTTPMethod
  path: AtomName
  headers: AtomName ‚Ü¶ AtomName
  body: AtomName
  query_params: AtomName ‚Ü¶ AtomName
where
  request_id > 0
  path ‚â† ""
end

schema HTTPResponse
  response_id: ‚Ñï‚ÇÅ
  request_id: ‚Ñï‚ÇÅ
  status_code: HTTPStatus
  headers: AtomName ‚Ü¶ AtomName
  body: AtomName
where
  response_id > 0
  request_id > 0
  status_code ‚àà 100..599
end

(*
 * HandleHTTPRequest: Process HTTP REST API request
 *)

schema HandleHTTPRequest
  ŒûAtomSpaceState
  request: HTTPRequest
  response!: HTTPResponse
where
  (* Route based on path and method *)
  
  (* GET /api/v1/atoms/:id *)
  request.method = GET ‚àß matches(request.path, "/api/v1/atoms/*") ‚üπ
    let atom_id = extract_id(request.path) in
    atom_id ‚àà dom atoms ‚üπ
      response! = HTTPResponse {
        response_id = generate_response_id(),
        request_id = request.request_id,
        status_code = 200,
        headers = {"Content-Type" ‚Ü¶ "application/json"},
        body = atom_to_json(atoms(atom_id))
      }
  
  (* POST /api/v1/atoms *)
  request.method = POST ‚àß request.path = "/api/v1/atoms" ‚üπ
    let atom_data = parse_json(request.body) in
    let new_atom = create_atom_from_data(atom_data) in
    let atom_id = add_atom(new_atom) in
      response! = HTTPResponse {
        response_id = generate_response_id(),
        request_id = request.request_id,
        status_code = 201,
        headers = {"Content-Type" ‚Ü¶ "application/json",
                   "Location" ‚Ü¶ "/api/v1/atoms/" + str(atom_id)},
        body = atom_to_json(atoms(atom_id))
      }
  
  (* GET /api/v1/query *)
  request.method = GET ‚àß request.path = "/api/v1/query" ‚üπ
    let pattern_str = request.query_params("pattern") in
    let pattern = parse_pattern(pattern_str) in
    let solutions = execute_query(pattern, atoms) in
      response! = HTTPResponse {
        response_id = generate_response_id(),
        request_id = request.request_id,
        status_code = 200,
        headers = {"Content-Type" ‚Ü¶ "application/json"},
        body = solutions_to_json(solutions)
      }
end

(* ========================================================================
 * INTER-PROCESS COMMUNICATION (IPC)
 * ======================================================================== *)

(*
 * Mach IPC Message Contract
 *)

schema MachIPCMessage
  msg_id: ‚Ñï‚ÇÅ
  source_port: PortID
  dest_port: PortID
  msg_type: AtomName
  payload: seq ‚Ñï          (* Raw bytes *)
  size: ‚Ñï‚ÇÅ
where
  msg_id > 0
  source_port > 0
  dest_port > 0
  size = #payload
  size ‚â§ 8192             (* Max message size *)
end

(*
 * SendIPCMessage: Send message via Mach IPC
 *)

schema SendIPCMessage
  ŒîCogNumachState
  message: MachIPCMessage
  success!: ùîπ
where
  (* Pre-conditions *)
  message.source_port ‚àà dom ports
  message.dest_port ‚àà dom ports
  ports(message.source_port).send_right
  ports(message.dest_port).receive_right
  
  (* Check queue capacity *)
  let dest_queue = ports(message.dest_port) in
  dest_queue.current_queue_size < dest_queue.queue_limit ‚üπ
    (* Enqueue message *)
    ports' = ports ‚äï {message.dest_port ‚Ü¶ 
      dest_queue ‚äï {
        current_queue_size = dest_queue.current_queue_size + 1
      }} ‚àß
    success! = true
  
  dest_queue.current_queue_size ‚â• dest_queue.queue_limit ‚üπ
    (* Queue full *)
    ports' = ports ‚àß
    success! = false
end

(*
 * ReceiveIPCMessage: Receive message via Mach IPC
 *)

schema ReceiveIPCMessage
  ŒîCogNumachState
  dest_port: PortID
  timeout: ‚Ñï              (* Milliseconds, 0 = no wait *)
  message!: MachIPCMessage
  success!: ùîπ
where
  (* Pre-conditions *)
  dest_port ‚àà dom ports
  ports(dest_port).receive_right
  
  (* Check if message available *)
  let port_queue = ports(dest_port) in
  port_queue.current_queue_size > 0 ‚üπ
    (* Dequeue message *)
    message! = dequeue_message(dest_port) ‚àß
    ports' = ports ‚äï {dest_port ‚Ü¶ 
      port_queue ‚äï {
        current_queue_size = port_queue.current_queue_size - 1
      }} ‚àß
    success! = true
  
  port_queue.current_queue_size = 0 ‚üπ
    (* No message available *)
    ports' = ports ‚àß
    success! = false ‚àß
    timeout = 0  (* Non-blocking *)
end

(* ========================================================================
 * TRANSLATOR INTERFACE (HURD)
 * ======================================================================== *)

(*
 * Translator operations following Hurd conventions
 *)

schema TranslatorOpen
  ŒûHurdCogState
  path: AtomName
  flags: AtomName
  translator_id!: TranslatorID
  success!: ùîπ
where
  (* Find translator for path *)
  let mount_point = find_mount_point(path, translators) in
  mount_point ‚àà dom translators ‚üπ
    let t = translators(mount_point) in
    t.is_active ‚üπ
      translator_id! = mount_point ‚àß
      success! = true
  
  mount_point ‚àâ dom translators ‚üπ
    success! = false
end

schema TranslatorRead
  ŒûHurdCogState
  translator_id: TranslatorID
  offset: ‚Ñï
  length: ‚Ñï‚ÇÅ
  data!: seq ‚Ñï
  bytes_read!: ‚Ñï
where
  (* Pre-conditions *)
  translator_id ‚àà dom translators
  translators(translator_id).is_active
  
  (* Send read request to translator process via IPC *)
  let t = translators(translator_id) in
  let request = construct_read_request(offset, length) in
  let (response, success) = send_ipc_to_translator(t.backing_pid, request) in
  
  success ‚üπ
    data! = parse_read_response(response) ‚àß
    bytes_read! = #data!
  
  ¬¨success ‚üπ
    data! = ‚ü®‚ü© ‚àß
    bytes_read! = 0
end

schema TranslatorWrite
  ŒîHurdCogState
  translator_id: TranslatorID
  offset: ‚Ñï
  data: seq ‚Ñï
  bytes_written!: ‚Ñï
  success!: ùîπ
where
  (* Pre-conditions *)
  translator_id ‚àà dom translators
  translators(translator_id).is_active
  ¬¨translators(translator_id).read_only
  
  (* Send write request to translator process via IPC *)
  let t = translators(translator_id) in
  let request = construct_write_request(offset, data) in
  let (response, write_success) = 
    send_ipc_to_translator(t.backing_pid, request) in
  
  write_success ‚üπ
    bytes_written! = parse_write_response(response) ‚àß
    success! = true
  
  ¬¨write_success ‚üπ
    bytes_written! = 0 ‚àß
    success! = false
end

(* ========================================================================
 * COGNITIVE CACHE INTEGRATION
 * ======================================================================== *)

(*
 * Cognitive cache operations that use STI for cache management
 *)

schema UpdateCognitiveCache
  ŒîHurdCogState
  accessed_inode: InodeNumber
where
  (* Pre-condition *)
  accessed_inode ‚àà dom file_system
  
  (* Update access frequency *)
  accessed_inode ‚àà cognitive_cache.cached_inodes ‚üπ
    cognitive_cache.access_frequency' = 
      cognitive_cache.access_frequency ‚äï {accessed_inode ‚Ü¶ 
        (cognitive_cache.access_frequency(accessed_inode) + 1)}
  
  (* Add to cache if not present *)
  accessed_inode ‚àâ cognitive_cache.cached_inodes ‚üπ
    #cognitive_cache.cached_inodes < cognitive_cache.max_cache_size ‚üπ
      cognitive_cache.cached_inodes' = 
        cognitive_cache.cached_inodes ‚à™ {accessed_inode} ‚àß
      cognitive_cache.access_frequency' = 
        cognitive_cache.access_frequency ‚à™ {accessed_inode ‚Ü¶ 1}
  
  (* Update STI based on access frequency *)
  let freq = cognitive_cache.access_frequency'(accessed_inode) in
  cognitive_cache.sti_scores' = 
    cognitive_cache.sti_scores ‚äï {accessed_inode ‚Ü¶ 
      compute_sti_from_frequency(freq)}
end

schema EvictFromCognitiveCache
  ŒîHurdCogState
where
  (* Evict lowest STI items when cache is full *)
  #cognitive_cache.cached_inodes ‚â• cognitive_cache.max_cache_size ‚üπ
    let sorted_by_sti = 
      sort_by_sti_asc(cognitive_cache.cached_inodes) in
    let eviction_count = 
      #cognitive_cache.cached_inodes div 10 in  (* Evict 10% *)
    let to_evict = take eviction_count sorted_by_sti in
    
    cognitive_cache.cached_inodes' = 
      cognitive_cache.cached_inodes \ to_evict ‚àß
    cognitive_cache.access_frequency' = 
      to_evict ‚©§ cognitive_cache.access_frequency ‚àß
    cognitive_cache.sti_scores' = 
      to_evict ‚©§ cognitive_cache.sti_scores
end

(* ========================================================================
 * EXTERNAL IDE INTEGRATION (LANGUAGE SERVER PROTOCOL)
 * ======================================================================== *)

(*
 * Language Server Protocol (LSP) integration
 *)

[LSPMessageType]
LSPMessageType ::= Initialize | Completion | Hover | Definition | 
                   Diagnostic | CodeAction

schema LSPMessage
  msg_id: ‚Ñï‚ÇÅ
  msg_type: LSPMessageType
  uri: AtomName            (* File URI *)
  position: (‚Ñï √ó ‚Ñï)        (* Line, column *)
  content: AtomName
where
  msg_id > 0
  uri ‚â† ""
  let (line, col) = position in
    line ‚â• 0 ‚àß col ‚â• 0
end

schema HandleLSPCompletion
  ŒûAtomSpaceState
  ŒûCogBoltState
  request: LSPMessage
  completions!: seq AtomName
where
  request.msg_type = Completion
  
  (* Extract code context *)
  let file_content = read_file(request.uri) in
  let (line, col) = request.position in
  let context = extract_context(file_content, line, col) in
  
  (* Query atomspace for relevant patterns *)
  let pattern = context_to_pattern(context) in
  let solutions = execute_query(pattern, atoms) in
  
  (* Generate completions *)
  completions! = solutions_to_completions(solutions)
end

(* ========================================================================
 * EVENT-DRIVEN INTEGRATION
 * ======================================================================== *)

(*
 * Webhook receiver for external events
 *)

schema WebhookEvent
  event_id: ‚Ñï‚ÇÅ
  source_url: AtomName
  event_type: AtomName
  payload: ‚Ñô KeyValuePair
  signature: AtomName      (* HMAC signature for verification *)
  timestamp: Timestamp
where
  event_id > 0
  source_url ‚â† ""
  event_type ‚â† ""
end

schema ProcessWebhook
  ŒîEventQueue
  webhook: WebhookEvent
  verified: ùîπ
  success!: ùîπ
where
  (* Verify webhook signature *)
  verified = verify_webhook_signature(
    webhook.payload,
    webhook.signature
  )
  
  (* Process verified webhooks *)
  verified ‚üπ
    let cognitive_event = webhook_to_cognitive_event(webhook) in
    PublishEvent(cognitive_event) ‚àß
    success! = true
  
  ¬¨verified ‚üπ
    success! = false ‚àß
    events' = events
end

(* ========================================================================
 * END OF INTEGRATION CONTRACTS SPECIFICATION
 * ======================================================================== *)

(*
 * This integration contracts specification defines:
 * 
 * 1. External LLM integration (Mistral, Llama, GPT)
 * 2. Storage backend contracts (RocksDB, PostgreSQL, IPFS)
 * 3. Network protocol integration (MCP, HTTP REST API)
 * 4. Inter-process communication (Mach IPC)
 * 5. Translator interface (Hurd filesystem abstraction)
 * 6. Cognitive cache management
 * 7. Language Server Protocol (LSP) for IDE integration
 * 8. Event-driven integration (webhooks, message queues)
 * 
 * All integration points specify precise contracts with
 * pre-conditions, post-conditions, and error handling.
 *)
