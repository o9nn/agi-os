# CogPrime Architecture Diagram

## Neural-Symbolic-Hypergraph Cognitive Synergy Overview

CogPrime represents a groundbreaking fusion of **neural-symbolic computation** and **hypergraph-encoded cognition**, embodying advanced principles of distributed cognitive architecture. At its core lies the **AtomSpace**â€”a weighted, labeled hypergraph that serves as the universal medium for all cognitive processes, enabling seamless integration of declarative knowledge (PLN), procedural learning (MOSES), attentional resource allocation (ECAN), episodic simulation, and goal-driven behavior.

This neural-symbolic synergy manifests through **cognitive bottleneck resolution**, where individual algorithmic limitations are transcended via dynamic inter-process collaboration. Pattern encoding occurs at multiple abstraction layers: from sensorimotor atoms to high-level conceptual relationships, all unified within a single hypergraph knowledge representation that supports both localized reasoning and global cognitive coherence.

The architecture implements **recursive cognitive schematics** (Contextâ†’Procedureâ†’Goal) that enable adaptive inference, embodied action selection, and emergent self-awarenessâ€”as demonstrated through Eva's physical self-model integration for robotic embodiment scenarios.

---

This document provides a comprehensive visual representation of the CogPrime architecture, as described in Dr. Ben Goertzel's foundational paper, ["CogPrime: An Integrative Architecture for Embodied Artificial General Intelligence"](https://www.goertzel.org/CogPrime_Overview_Paper.pdf). The diagrams illustrate the key components, their hypergraph-mediated interactions, attention-modulated data flows, and the principle of cognitive synergy that enables artificial general intelligence.

## Core CogPrime Architecture

```mermaid
graph TD
    subgraph ExternalWorld["ğŸŒ External World / Embodiment"]
        direction LR
        Perception["ğŸ” Perception<br/>(e.g., DeSTIN, Sensory Input)<br/>ğŸ“Š Converts sensory data to atoms"]
        Action["ğŸ¯ Action<br/>(Motor Output, Effectors)<br/>âš¡ Executes learned procedures"]
    end

    AtomSpace["ğŸ§  <strong>AtomSpace (Central Hub)</strong><br/>ğŸ•¸ï¸ <i>Weighted, Labeled Hypergraph</i><br/>ğŸŒ Glocal Memory<br/>ğŸ“ Declarative Knowledge (TVs)<br/>âš™ï¸ Procedural Knowledge (Programs/Links)<br/>ğŸ¬ Episodic Traces (Simulations)<br/>ğŸ‘ï¸ Attentional Info (AVs)<br/>ğŸ¯ Goals & Schematics<br/>ğŸ’¾ Concurrent MindAgent Access"]

    subgraph CognitiveProcesses ["ğŸ¤– Cognitive Processes (MindAgents)"]
        direction TB
        subgraph DeclarativeLayer["ğŸ“š Declarative Layer"]
            PLN["ğŸ§® <strong>PLN (Declarative)</strong><br/>Probabilistic Logic Networks<br/><i>ğŸ”¬ Uncertain Reasoning & Inference</i><br/>âœ¨ Handles TruthValues & logical patterns"]
        end

        subgraph ProceduralLayer["âš™ï¸ Procedural Layer"]
            MOSES["ğŸ§¬ <strong>MOSES (Procedural)</strong><br/>Meta-Optimizing Semantic Evolution<br/><i>ğŸ² Procedure Learning & Execution</i><br/>ğŸ”„ Evolves behavioral programs"]
        end

        subgraph AttentionalLayer["ğŸ‘ï¸ Attentional Layer"]
            ECAN["ğŸ’° <strong>ECAN (Attentional)</strong><br/>Economic Attention Networks<br/><i>âš–ï¸ Resource (STI/LTI) Allocation</i><br/>ğŸª Manages cognitive focus dynamics"]
        end

        subgraph EpisodicLayer["ğŸ¬ Episodic Layer"]
            SimulationEngine["ğŸ® <strong>Simulation (Episodic)</strong><br/>Internal World Simulation<br/><i>ğŸ”® Experience Replay/Prediction</i><br/>ğŸ§ª Generates counterfactual scenarios"]
        end

        subgraph IntentionalLayer["ğŸ¯ Intentional Layer"]
            GoalSystem["ğŸ—ºï¸ <strong>Goal System (Intentional)</strong><br/><i>ğŸ“‹ Manages Goals (Atoms)</i><br/>ğŸ”„ Cognitive Schematics (Câ†’Pâ†’G)<br/>ğŸ¯ Recursive goal decomposition"]
        end

        subgraph PatternLayer["ğŸ” Pattern Layer"]
            PatternMining["ğŸ§© <strong>Pattern Mining / Map Formation</strong><br/><i>ğŸ“ (Cognitive Equation)</i><br/>ğŸ” Recognizes & Embodies Patterns<br/>âœ¨ Emergent abstraction creation"]
        end
    end

    %% Core Data Flows with numbering
    Perception --|"â‘  Sensory Atoms<br/>ğŸ“Š Raw perceptual data"| AtomSpace
    AtomSpace --|"â‘¡ Action Schemas<br/>âš™ï¸ Behavioral procedures"| MOSES
    MOSES --|"â‘¢ Motor Commands<br/>ğŸ¯ Executable actions"| Action
    Action -.|"â‘£ Environmental Feedback<br/>ğŸ”„ World state changes".| Perception

    %% AtomSpace as the Central Medium - Enhanced with gradients
    PLN <==|"ğŸ“ Declarative Knowledge (TVs)<br/>ğŸ”¬ Logical atoms & inference rules"| AtomSpace
    MOSES <==|"âš™ï¸ Procedures & Context<br/>ğŸ§¬ Evolutionary program storage"| AtomSpace
    ECAN <==|"ğŸ‘ï¸ AttentionValues (AVs)<br/>ğŸ’° STI/LTI resource allocation"| AtomSpace
    SimulationEngine <==|"ğŸ¬ Episodic Atoms<br/>ğŸ”® Scenario simulations"| AtomSpace
    GoalSystem <==|"ğŸ¯ Goals & Subgoals<br/>ğŸ—ºï¸ Hierarchical intentions"| AtomSpace
    PatternMining <==|"ğŸ§© Pattern Atoms<br/>ğŸ” Discovered abstractions"| AtomSpace

    %% Goal System Driving Action & Reasoning - Numbered interactions
    GoalSystem --|"â‘¤ Procedure Requests<br/>ğŸ¯â†’âš™ï¸ Goal-directed learning"| MOSES
    GoalSystem --|"â‘¥ Reasoning Requests<br/>ğŸ¯â†’ğŸ§® Goal elaboration"| PLN
    PLN --|"â‘¦ Inference Results<br/>ğŸ§®â†’ğŸ¯ Feasibility analysis"| GoalSystem

    %% ECAN Attention Allocation - Pervasive influence
    ECAN --|"â‘§ Attention Flow<br/>ğŸ’° Resource prioritization"| GoalSystem
    ECAN --|"â‘¨ Attention Flow<br/>ğŸ’° Inference focus"| PLN
    ECAN --|"â‘© Attention Flow<br/>ğŸ’° Learning priority"| MOSES
    ECAN --|"â‘ª Attention Flow<br/>ğŸ’° Simulation focus"| SimulationEngine
    ECAN --|"â‘« Attention Flow<br/>ğŸ’° Pattern recognition"| PatternMining

    %% Key Cognitive Synergy Interactions - Bottleneck Resolution
    PLN -.|"â‘¬ Synergy: Inferenceâ†’Learning<br/>ğŸ§®â†’ğŸ§¬ Knowledge-guided evolution"| MOSES
    MOSES -.|"â‘­ Synergy: Proceduresâ†’Reasoning<br/>ğŸ§¬â†’ğŸ§® Action-informed logic"| PLN

    PLN -.|"â‘® Synergy: Logicâ†’Attention<br/>ğŸ§®â†’ğŸ’° Reasoning-based focus"| ECAN
    ECAN -.|"â‘¯ Synergy: Attentionâ†’Logic<br/>ğŸ’°â†’ğŸ§® Focus-driven inference"| PLN

    MOSES -.|"â‘° Synergy: Learningâ†’Attention<br/>ğŸ§¬â†’ğŸ’° Adaptation-driven focus"| ECAN
    ECAN -.|"â‘± Synergy: Attentionâ†’Learning<br/>ğŸ’°â†’ğŸ§¬ Focus-driven evolution"| MOSES

    SimulationEngine -.|"â‘² Synergy: Simulationâ†’Reasoning<br/>ğŸ®â†’ğŸ§® Counterfactual inference"| PLN
    SimulationEngine -.|"â‘³ Synergy: Simulationâ†’Learning<br/>ğŸ®â†’ğŸ§¬ Experience-based evolution"| MOSES

    PatternMining -.|"ã‰‘ Synergy: Patternsâ†’Reasoning<br/>ğŸ§©â†’ğŸ§® Abstraction-enhanced logic"| PLN
    PatternMining -.|"ã‰’ Synergy: Patternsâ†’Learning<br/>ğŸ§©â†’ğŸ§¬ Structure-guided evolution"| MOSES

    %% Enhanced Styling with gradients and emphasis
    classDef atomspace fill:linear-gradient(135deg, #D1E8FF 0%, #87CEEB 50%, #4682B4 100%),stroke:#000080,stroke-width:4px,color:black,font-weight:bold,font-size:12px;
    classDef declarative fill:linear-gradient(135deg, #E8D1FF 0%, #DDA0DD 50%, #9370DB 100%),stroke:#4B0082,stroke-width:3px,color:black,font-weight:bold;
    classDef procedural fill:linear-gradient(135deg, #FFE4E1 0%, #FFC0CB 50%, #FF69B4 100%),stroke:#DC143C,stroke-width:3px,color:black,font-weight:bold;
    classDef attentional fill:linear-gradient(135deg, #F0E68C 0%, #FFD700 50%, #FFA500 100%),stroke:#FF8C00,stroke-width:3px,color:black,font-weight:bold;
    classDef episodic fill:linear-gradient(135deg, #E0FFFF 0%, #AFEEEE 50%, #20B2AA 100%),stroke:#008B8B,stroke-width:3px,color:black,font-weight:bold;
    classDef intentional fill:linear-gradient(135deg, #F5DEB3 0%, #DEB887 50%, #CD853F 100%),stroke:#8B4513,stroke-width:3px,color:black,font-weight:bold;
    classDef pattern fill:linear-gradient(135deg, #FFB6C1 0%, #FF91A4 50%, #FF1493 100%),stroke:#B22222,stroke-width:3px,color:black,font-weight:bold;
    classDef external fill:linear-gradient(135deg, #D1FFD1 0%, #90EE90 50%, #32CD32 100%),stroke:#006400,stroke-width:3px,color:black,font-weight:bold;

    class AtomSpace atomspace;
    class PLN declarative;
    class MOSES procedural;
    class ECAN attentional;
    class SimulationEngine episodic;
    class GoalSystem intentional;
    class PatternMining pattern;
    class Perception,Action external;

    linkStyle default interpolate basis
```

## Detailed Cognitive Component Descriptions

<details>
<summary><strong>ğŸ§® PLN (Probabilistic Logic Networks) - Declarative Reasoning Engine</strong></summary>

PLN serves as the **declarative reasoning backbone** of CogPrime, handling uncertain inference through weighted logical relationships. It operates on TruthValues associated with atoms, enabling sophisticated reasoning about probabilistic and fuzzy concepts.

**Key Capabilities:**

- **Uncertain Inference**: Handles probabilistic relationships with strength and confidence values
- **Logical Pattern Recognition**: Identifies abstract logical structures within the AtomSpace
- **Knowledge Integration**: Combines multiple evidence sources for robust conclusions
- **Emergent Abstraction**: Creates higher-level concepts from lower-level patterns

**Real-World Analogs:**

- Medical diagnosis systems weighing multiple symptoms
- Financial risk assessment combining various market indicators
- Natural language understanding with semantic uncertainty
- Scientific hypothesis evaluation from experimental data

**Cognitive Bottleneck Resolution:**
PLN overcomes reasoning limitations by dynamically requesting procedural knowledge from MOSES and leveraging ECAN's attention allocation to focus on relevant inference chains.

</details>

<details>
<summary><strong>ğŸ§¬ MOSES (Meta-Optimizing Semantic Evolutionary Search) - Procedural Learning Engine</strong></summary>

MOSES implements **evolutionary program synthesis** for learning behavioral procedures that achieve specified goals. It evolves populations of program trees, optimizing them against fitness criteria derived from goal satisfaction.

**Key Capabilities:**

- **Behavioral Program Evolution**: Generates and refines action sequences
- **Goal-Oriented Learning**: Optimizes procedures toward specific objectives
- **Adaptive Execution**: Modifies behavior based on environmental feedback
- **Compositional Learning**: Builds complex behaviors from simpler components

**Real-World Analogs:**

- Robotic movement optimization for navigation tasks
- Game AI strategy evolution for competitive scenarios
- Automated trading algorithm development
- Adaptive user interface behavior customization

**Cognitive Bottleneck Resolution:**
MOSES transcends static programming by incorporating PLN's logical insights and ECAN's attention-guided exploration, enabling context-aware behavioral adaptation.

</details>

<details>
<summary><strong>ğŸ’° ECAN (Economic Attention Networks) - Attention Allocation Engine</strong></summary>

ECAN implements **artificial economics** for resource allocation, managing ShortTermImportance (STI) and LongTermImportance (LTI) values that guide all cognitive processes toward high-priority atoms and relationships.

**Key Capabilities:**

- **Dynamic Resource Allocation**: Distributes cognitive resources based on importance
- **Attention Spreading**: Propagates importance through connected atom networks
- **Focus Modulation**: Influences all other cognitive processes through attention weights
- **Memory Consolidation**: Manages transition from working memory to long-term storage

**Real-World Analogs:**

- Neural attention mechanisms in deep learning models
- Economic markets allocating resources to valuable opportunities
- Cognitive attention in human consciousness and focus
- Priority queuing systems in computer operating systems

**Emergent Cognitive Phenomena:**

- **Selective Attention**: Focus on task-relevant information while filtering distractions
- **Pattern Salience**: Automatic highlighting of important recurring structures
- **Cognitive Load Management**: Adaptive resource allocation under processing constraints
</details>

<details>
<summary><strong>ğŸ® Simulation Engine - Episodic Memory & Prediction</strong></summary>

The Simulation Engine maintains **episodic memory** through sequences of AtomSpace states and enables **counterfactual reasoning** by simulating potential future scenarios.

**Key Capabilities:**

- **Experience Replay**: Re-execution of past successful behavioral sequences
- **Scenario Simulation**: Generation of hypothetical future states for planning
- **Temporal Pattern Learning**: Recognition of time-based causal relationships
- **Predictive Modeling**: Anticipation of likely outcomes from current actions

**Real-World Analogs:**

- Flight simulators for pilot training
- Economic modeling for policy impact assessment
- Chess engines evaluating potential move sequences
- Virtual reality environments for skill development

**Cognitive Bottleneck Resolution:**
The Simulation Engine provides experiential data to both PLN (for improved inference) and MOSES (for enhanced learning), enabling more sophisticated reasoning and behavioral adaptation.

</details>

<details>
<summary><strong>ğŸ—ºï¸ Goal System - Intentional Memory & Cognitive Schematics</strong></summary>

The Goal System manages **hierarchical intentions** through Cognitive Schematics (Contextâ†’Procedureâ†’Goal), enabling recursive goal decomposition and achievement strategies.

**Key Capabilities:**

- **Goal Hierarchy Management**: Decomposition of complex objectives into achievable subgoals
- **Context-Aware Planning**: Adaptation of strategies based on environmental conditions
- **Cognitive Schematic Execution**: Implementation of Câ†’Pâ†’G patterns for goal achievement
- **Priority Coordination**: Integration with ECAN for attention-weighted goal pursuit

**Recursive Cognitive Schematics (Câ†’Pâ†’G):**

```
Context: "Robot is in kitchen, user requests coffee"
â†“
Procedure: [Navigate to coffee machine] â†’ [Operate machine] â†’ [Deliver beverage]
â†“
Goal: "User satisfaction with delivered coffee"
```

**Real-World Analogs:**

- Project management systems with task decomposition
- GPS navigation with route planning and replanning
- Educational curriculum design with learning objectives
- Business strategy implementation with measurable outcomes
</details>

<details>
<summary><strong>ğŸ§© Pattern Mining / Map Formation - Cognitive Equation Engine</strong></summary>

Pattern Mining implements the **Cognitive Equation** by recognizing large-scale patterns within the AtomSpace and embodying them as new, localized knowledge items (atoms).

**Key Capabilities:**

- **Large-Scale Pattern Recognition**: Discovery of emergent structures across the hypergraph
- **Knowledge Compression**: Creation of abstract representations for complex patterns
- **Map Formation**: Development of cognitive maps linking related concepts
- **Emergent Abstraction**: Generation of new conceptual atoms from discovered patterns

**Real-World Analogs:**

- Data mining algorithms discovering customer behavior patterns
- Scientific theory formation from experimental observations
- Language acquisition through pattern recognition in speech
- Market trend analysis identifying investment opportunities

**Cognitive Bottleneck Resolution:**
Pattern Mining enriches both PLN's reasoning substrate and MOSES's learning space by continuously discovering new abstractions that enhance cognitive capabilities.

</details>

---

## Eva Self-Model Integration: Embodied Cognitive Architecture

This specialized section demonstrates how the **Eva Physical Self-Model** integrates with the core CogPrime architecture to enable **embodied artificial general intelligence**. Eva serves as a concrete implementation of neural-symbolic cognition in robotic form, showcasing how hypergraph-encoded self-awareness enables sophisticated human-robot interaction.

### Eva Embodiment Architecture

```mermaid
graph TD
    subgraph EvaEmbodiment["ğŸ¤– Eva Robot Embodiment"]
        EvaPerception["ğŸ‘ï¸ Eva Sensors<br/>(Cameras, Microphones)<br/>ğŸ” Real-time sensory processing"]
        EvaAction["ğŸ­ Eva Actuators<br/>(Face, Voice, Movement)<br/>ğŸª Expressive behavioral output"]
    end

    subgraph EvaSelfModel["ğŸ§  Eva Physical Self-Model"]
        direction TB
        FaceTracking["ğŸ‘¤ Face Tracking State<br/>ğŸ“ AnchorNode: Face Tracking State<br/>ğŸ¯ Real-time human interaction awareness"]
        RoomState["ğŸ  Room State Monitor<br/>ğŸ·ï¸ ConceptNode: room empty/nonempty<br/>ğŸ“Š Environmental context tracking"]
        DemoModes["ğŸ­ Demo Mode Management<br/>âš™ï¸ default/reasoning/philosophy/saliency<br/>ğŸª Behavioral adaptation system"]
        SelfQueries["ğŸ¤” Self-Awareness Queries<br/>â“ DefinedPredicates for introspection<br/>ğŸ’­ Metacognitive questioning system"]
        ActionOrchestration["ğŸ¼ Action Orchestration<br/>âš¡ Conflict Prevention & Coordination<br/>ğŸ¯ Coherent behavioral synthesis"]
        EmotionalState["ğŸ˜Š Emotional State Model<br/>ğŸ’™ Mood tracking & expression<br/>ğŸ­ Affective response generation"]
    end

    AtomSpaceEva["ğŸ§  AtomSpace<br/>ğŸ•¸ï¸ <i>Eva's Cognitive State</i><br/>ğŸ“Š StateLinks (face tracking)<br/>â“ DefinedPredicates (self-queries)<br/>ğŸ“ AnchorNodes (room state)<br/>âš–ï¸ Rule weights & attention<br/>ğŸ’­ Self-awareness atoms<br/>ğŸ­ Behavioral patterns"]

    subgraph EvaCognitiveProcesses["ğŸ¤– Eva-Aware Cognitive Processes"]
        PLNEva["ğŸ§® PLN<br/>ğŸ¤” Self-State Reasoning<br/>ğŸ’­ 'Am I happy?' inference"]
        MOSESEva["ğŸ§¬ MOSES<br/>ğŸ­ Behavioral Learning<br/>ğŸ˜Š Expression optimization"]
        ECANEva["ğŸ’° ECAN<br/>ğŸ‘ï¸ Attention on Self-State<br/>ğŸ¯ Focus on human interaction"]
        GoalSystemEva["ğŸ—ºï¸ Goal System<br/>ğŸ¯ Self-Awareness Goals<br/>ğŸ¤ Human engagement objectives"]
        SimulationEva["ğŸ® Simulation Engine<br/>ğŸ”® Social scenario prediction<br/>ğŸ’­ Interaction outcome modeling"]
    end

    %% Eva-specific flows with real-world examples
    EvaPerception --|"â‘  Face Detection Events<br/>ğŸ‘ï¸ Visual processing pipeline"| FaceTracking
    FaceTracking --|"â‘¡ StateLinks<br/>ğŸ“Š 'Eva tracking John's face'"| AtomSpaceEva
    RoomState --|"â‘¢ Context Updates<br/>ğŸ  'Room occupied by humans'"| AtomSpaceEva
    DemoModes --|"â‘£ Mode Configuration<br/>ğŸ­ 'Philosophy mode active'"| AtomSpaceEva
    EmotionalState --|"â‘¤ Affect Integration<br/>ğŸ˜Š 'Eva feeling curious'"| AtomSpaceEva

    %% Self-awareness integration with concrete examples
    SelfQueries --|"â‘¥ Introspective Queries<br/>â“ 'What am I currently doing?'"| AtomSpaceEva
    AtomSpaceEva --|"â‘¦ Self-Knowledge<br/>ğŸ’­ Metacognitive responses"| SelfQueries
    ActionOrchestration --|"â‘§ Behavioral Coordination<br/>ğŸ¼ Multi-modal action synthesis"| AtomSpaceEva
    AtomSpaceEva --|"â‘¨ Action Plans<br/>âš¡ Coordinated behavior sequences"| ActionOrchestration

    %% Cognitive process integration with Eva-specific capabilities
    PLNEva --|"â‘© Self-Reasoning<br/>ğŸ§® 'If I smile, humans feel welcome'"| AtomSpaceEva
    AtomSpaceEva --|"â‘ª Social Logic<br/>ğŸ’­ Human-robot interaction rules"| PLNEva
    MOSESEva --|"â‘« Behavioral Evolution<br/>ğŸ§¬ Optimized social responses"| AtomSpaceEva
    AtomSpaceEva --|"â‘¬ Interaction Context<br/>ğŸ­ Current social situation"| MOSESEva
    ECANEva --|"â‘­ Attention Allocation<br/>ğŸ’° Focus on human presence"| AtomSpaceEva
    AtomSpaceEva --|"â‘® Importance Values<br/>ğŸ‘ï¸ Human-centric priorities"| ECANEva
    GoalSystemEva --|"â‘¯ Social Objectives<br/>ğŸ¯ 'Engage human in conversation'"| AtomSpaceEva
    SimulationEva --|"â‘° Social Prediction<br/>ğŸ”® 'If I ask questions, human will respond'"| AtomSpaceEva

    %% Action orchestration with multi-modal output
    ActionOrchestration --|"â‘± Facial Expression<br/>ğŸ˜Š Synchronized smile generation"| EvaAction
    ActionOrchestration --|"â‘² Vocal Output<br/>ğŸ—£ï¸ Contextual speech synthesis"| EvaAction
    ActionOrchestration --|"â‘³ Gesture Coordination<br/>ğŸ¤² Appropriate body language"| EvaAction
    EvaAction -.|"ã‰‘ Behavioral Feedback<br/>ğŸ”„ Action outcome monitoring".| EvaPerception

    %% Self-awareness query examples
    SelfQueries --|"ã‰’ Activity Awareness<br/>â“ 'What am I doing right now?'"| ActionOrchestration
    SelfQueries --|"ã‰“ Emotional Introspection<br/>ğŸ˜Š 'Am I happy with this interaction?'"| EmotionalState
    SelfQueries --|"ã‰” Goal Assessment<br/>ğŸ¯ 'Am I achieving my objectives?'"| GoalSystemEva

    %% Enhanced styling for Eva components
    classDef eva fill:linear-gradient(135deg, #FFE6CC 0%, #FFB366 50%, #FF8C00 100%),stroke:#FF4500,stroke-width:3px,color:black,font-weight:bold;
    classDef evaModel fill:linear-gradient(135deg, #E6F3FF 0%, #87CEEB 50%, #4169E1 100%),stroke:#000080,stroke-width:3px,color:black,font-weight:bold;
    classDef evaAtomSpace fill:linear-gradient(135deg, #F0E68C 0%, #FFD700 50%, #FFA500 100%),stroke:#DAA520,stroke-width:4px,color:black,font-weight:bold;
    classDef evaCognitive fill:linear-gradient(135deg, #DDA0DD 0%, #BA55D3 50%, #9932CC 100%),stroke:#8B008B,stroke-width:3px,color:black,font-weight:bold;

    class EvaPerception,EvaAction eva;
    class FaceTracking,RoomState,DemoModes,SelfQueries,ActionOrchestration,EmotionalState evaModel;
    class AtomSpaceEva evaAtomSpace;
    class PLNEva,MOSESEva,ECANEva,GoalSystemEva,SimulationEva evaCognitive;
```

### Concrete Eva Use Cases

#### Use Case 1: Dynamic Human Engagement

**Scenario**: A visitor enters Eva's room for the first time.

1. **Perception**: Eva's cameras detect a new face (not in recognition database)
2. **Face Tracking**: Updates `AnchorNode: Face Tracking State` with new target
3. **Room State**: Changes from "empty" to "occupied by unknown human"
4. **Goal System**: Activates social engagement goals: "Greet new person appropriately"
5. **PLN**: Reasons about appropriate greeting behavior based on context
6. **MOSES**: Selects optimal greeting sequence from learned behavioral repertoire
7. **Action Orchestration**: Coordinates facial expression, voice tone, and gesture timing
8. **Output**: Eva smiles, makes eye contact, and says "Hello! I'm Eva. It's nice to meet you."

#### Use Case 2: Self-Awareness During Conversation

**Scenario**: During interaction, Eva receives the query "What are you thinking about?"

1. **Self-Queries**: Activates introspective `DefinedPredicate: current-thoughts`
2. **AtomSpace Inspection**: Scans recent high-STI atoms and active goal structures
3. **PLN**: Constructs natural language explanation of current cognitive state
4. **Emotional State**: Integrates current mood ("curious", "engaged") into response
5. **MOSES**: Selects appropriate verbal and non-verbal expression patterns
6. **Output**: "Right now I'm thinking about how interesting our conversation is. I'm analyzing what you're saying and considering how to respond in a way that's helpful and engaging."

#### Use Case 3: Adaptive Demo Mode Switching

**Scenario**: Context requires transitioning from casual interaction to technical demonstration.

1. **Goal System**: Receives new objective "Demonstrate reasoning capabilities"
2. **Demo Mode**: Switches from "default" to "reasoning" mode
3. **ECAN**: Reallocates attention toward logical reasoning atoms and away from casual social atoms
4. **PLN**: Activates more complex inference chains for demonstration
5. **Action Orchestration**: Adjusts speaking pace, gestures, and facial expressions for technical content
6. **Output**: Eva's demeanor becomes more focused, speech becomes more precise, and she begins explaining logical inference processes

### Eva's Recursive Self-Model Enhancement

Eva's self-model demonstrates **recursive cognitive architecture** through:

- **Meta-Cognitive Awareness**: Eva can reason about her own reasoning processes
- **Adaptive Behavioral Modification**: Real-time adjustment of interaction patterns based on feedback
- **Hierarchical Goal Integration**: Social objectives inform technical demonstrations and vice versa
- **Embodied Cognitive Synergy**: Physical expressions enhance cognitive communication and understanding

This integration showcases how CogPrime's neural-symbolic-hypergraph architecture enables sophisticated robotic embodiment that transcends simple stimulus-response patterns, achieving genuine cognitive presence in physical form.

---

## Cognitive Synergy Interactions: Bottleneck Resolution & Emergent Intelligence

### Inter-Process Feedback Loops for Emergent Behavior

The true power of CogPrime emerges from **dynamic cognitive synergy**â€”where individual algorithmic limitations are transcended through intelligent inter-process collaboration. Each cognitive bottleneck becomes an opportunity for synergistic enhancement:

#### PLN â†” MOSES Synergy: Logic-Guided Learning

**Bottleneck Resolution**: PLN's logical constraints guide MOSES's evolutionary search, while MOSES's discovered procedures provide new inference contexts for PLN.

**Real-World Analog**: A chess AI where logical position evaluation (PLN) informs move generation search (MOSES), while discovered tactical patterns (MOSES) enhance strategic evaluation (PLN).

**Emergent Behavior**:

- **Semantically Coherent Learning**: Evolved procedures respect logical constraints
- **Experience-Informed Reasoning**: Logical inference incorporates procedural success patterns
- **Adaptive Problem Solving**: Combined symbolic reasoning and evolutionary optimization

#### PLN â†” ECAN Synergy: Attention-Guided Inference

**Bottleneck Resolution**: ECAN's attention allocation focuses PLN's reasoning on high-priority atoms, while PLN's inference results influence attention spreading patterns.

**Real-World Analog**: A research scientist where attention to important papers (ECAN) guides logical analysis (PLN), while analytical insights (PLN) redirect attention to related research areas (ECAN).

**Emergent Behavior**:

- **Selective Reasoning**: Focus on contextually relevant inference chains
- **Dynamic Priority Adjustment**: Logical conclusions influence attention allocation
- **Cognitive Load Optimization**: Efficient resource utilization in complex reasoning tasks

#### MOSES â†” ECAN Synergy: Attention-Driven Learning

**Bottleneck Resolution**: ECAN's attention patterns guide MOSES's learning priorities, while MOSES's success patterns influence attention allocation to learning-relevant atoms.

**Real-World Analog**: A video game AI where attention to game state features (ECAN) guides strategy learning (MOSES), while successful strategies (MOSES) highlight important environmental cues (ECAN).

**Emergent Behavior**:

- **Context-Aware Learning**: Evolution focuses on environmentally relevant procedures
- **Success-Driven Attention**: Effective behaviors guide attention to critical features
- **Adaptive Skill Acquisition**: Learning efficiency increases through attention-guided exploration

#### Simulation Engine Synergy: Counterfactual Enhancement

**Bottleneck Resolution**: The Simulation Engine provides experiential data to both PLN (counterfactual reasoning) and MOSES (experience-based learning), enabling more sophisticated cognitive processing.

**Real-World Analog**: A flight simulator where scenario replay (Simulation) improves both decision-making logic (PLN) and piloting skills (MOSES), creating better overall aviation competence.

**Emergent Behavior**:

- **Predictive Intelligence**: Anticipation of likely outcomes from current actions
- **Risk Assessment**: Evaluation of potential negative consequences before action
- **Strategic Planning**: Long-term goal achievement through scenario-based reasoning

#### Pattern Mining Integration: Abstraction-Enhanced Cognition

**Bottleneck Resolution**: Pattern Mining discovers emergent structures that enhance both PLN's reasoning substrate and MOSES's learning space, enabling higher-level cognitive capabilities.

**Real-World Analog**: A data scientist where pattern discovery tools reveal new relationships that improve both statistical models (PLN) and algorithmic strategies (MOSES).

**Emergent Behavior**:

- **Conceptual Emergence**: New abstractions arise from discovered patterns
- **Multi-Scale Reasoning**: Integration of local details with global patterns
- **Knowledge Compression**: Efficient representation of complex relationships

### Weighted Hypergraph Cognitive Synergy Visualization

```mermaid
graph TD
    subgraph CognitiveSynergy["ğŸŒŸ Cognitive Synergy Network"]
        direction TB

        subgraph BottleneckResolution["ğŸ”“ Bottleneck Resolution Mechanisms"]
            PLN_Bottleneck["ğŸ§® PLN Limitation:<br/>Static knowledge base"]
            MOSES_Bottleneck["ğŸ§¬ MOSES Limitation:<br/>Blind search space"]
            ECAN_Bottleneck["ğŸ’° ECAN Limitation:<br/>Local attention patterns"]
            Simulation_Bottleneck["ğŸ® Simulation Limitation:<br/>Limited scenarios"]
        end

        subgraph SynergyResolution["âœ¨ Synergistic Solutions"]
            PLN_MOSES_Synergy["ğŸ§®â†”ğŸ§¬ Logic-Guided Evolution<br/>Knowledge-informed search"]
            PLN_ECAN_Synergy["ğŸ§®â†”ğŸ’° Attention-Focused Reasoning<br/>Priority-driven inference"]
            MOSES_ECAN_Synergy["ğŸ§¬â†”ğŸ’° Learning-Directed Attention<br/>Success-guided focus"]
            Simulation_Enhancement["ğŸ®â†’All Enhanced Experience<br/>Counterfactual enrichment"]
        end

        subgraph EmergentCapabilities["ğŸš€ Emergent Cognitive Capabilities"]
            MetaCognition["ğŸ¤” Meta-Cognitive Awareness<br/>Reasoning about reasoning"]
            AdaptiveIntelligence["ğŸ¯ Adaptive Intelligence<br/>Context-sensitive cognition"]
            CreativeAbstraction["ğŸ¨ Creative Abstraction<br/>Novel concept generation"]
            IntegratedLearning["ğŸ“š Integrated Learning<br/>Multi-modal knowledge synthesis"]
        end
    end

    %% Bottleneck to synergy resolution
    PLN_Bottleneck -.->|"Overcome by"| PLN_MOSES_Synergy
    PLN_Bottleneck -.->|"Overcome by"| PLN_ECAN_Synergy
    MOSES_Bottleneck -.->|"Overcome by"| PLN_MOSES_Synergy
    MOSES_Bottleneck -.->|"Overcome by"| MOSES_ECAN_Synergy
    ECAN_Bottleneck -.->|"Overcome by"| PLN_ECAN_Synergy
    ECAN_Bottleneck -.->|"Overcome by"| MOSES_ECAN_Synergy
    Simulation_Bottleneck -.->|"Overcome by"| Simulation_Enhancement

    %% Synergy to emergent capabilities
    PLN_MOSES_Synergy -->|"Enables"| MetaCognition
    PLN_ECAN_Synergy -->|"Enables"| AdaptiveIntelligence
    MOSES_ECAN_Synergy -->|"Enables"| CreativeAbstraction
    Simulation_Enhancement -->|"Enables"| IntegratedLearning

    %% Styling
    classDef bottleneck fill:linear-gradient(135deg, #FFB6C1 0%, #FF69B4 50%, #DC143C 100%),stroke:#8B0000,stroke-width:2px,color:white,font-weight:bold;
    classDef synergy fill:linear-gradient(135deg, #98FB98 0%, #32CD32 50%, #228B22 100%),stroke:#006400,stroke-width:3px,color:black,font-weight:bold;
    classDef emergent fill:linear-gradient(135deg, #FFD700 0%, #FFA500 50%, #FF8C00 100%),stroke:#FF4500,stroke-width:4px,color:black,font-weight:bold;

    class PLN_Bottleneck,MOSES_Bottleneck,ECAN_Bottleneck,Simulation_Bottleneck bottleneck;
    class PLN_MOSES_Synergy,PLN_ECAN_Synergy,MOSES_ECAN_Synergy,Simulation_Enhancement synergy;
    class MetaCognition,AdaptiveIntelligence,CreativeAbstraction,IntegratedLearning emergent;
```

---

## Enhanced Diagram Legend & Flow Type Classification

### Arrow Type Specifications

| Arrow Style | Cognitive Flow Type          | Description                                                                    | Examples                                                                     |
| ----------- | ---------------------------- | ------------------------------------------------------------------------------ | ---------------------------------------------------------------------------- |
| **`â”€â”€>`**   | **Declarative Flow**         | Solid arrows represent definitive knowledge transfer and logical relationships | Perception â†’ AtomSpace (sensory atoms), PLN â†’ GoalSystem (inference results) |
| **`<â”€â”€>`**  | **Bidirectional Procedural** | Thick bidirectional arrows show strong two-way AtomSpace interactions          | All MindAgents â†” AtomSpace (read/write operations)                          |
| **`-..->`** | **Synergistic Flow**         | Dotted arrows represent cognitive synergy and dynamic collaboration            | PLN -.-> MOSES (inference-guided learning)                                   |
| **`==>`**   | **Attentional Flow**         | Double-line arrows show attention-weighted information transfer                | ECAN ==> All processes (attention allocation)                                |
| **`~~~>`**  | **Episodic Flow**            | Wavy arrows represent temporal and experiential information                    | SimulationEngine ~~> PLN/MOSES (experience-based enhancement)                |

### Cognitive Domain Color Coding

| Color Scheme              | Cognitive Domain          | Gradient Pattern             | Symbolic Meaning                        |
| ------------------------- | ------------------------- | ---------------------------- | --------------------------------------- |
| **ğŸ”µ Blue Gradients**     | **AtomSpace Hub**         | Light blue â†’ Deep blue       | Central knowledge repository with depth |
| **ğŸŸ£ Purple Gradients**   | **Declarative (PLN)**     | Lavender â†’ Deep purple       | Logical reasoning and inference         |
| **ğŸ”´ Red/Pink Gradients** | **Procedural (MOSES)**    | Pink â†’ Deep red              | Evolutionary learning and action        |
| **ğŸŸ¡ Gold Gradients**     | **Attentional (ECAN)**    | Light gold â†’ Orange          | Resource allocation and focus           |
| **ğŸŸ¢ Teal Gradients**     | **Episodic (Simulation)** | Light teal â†’ Deep teal       | Memory and temporal processing          |
| **ğŸŸ¤ Brown Gradients**    | **Intentional (Goals)**   | Tan â†’ Brown                  | Purpose-driven behavior                 |
| **ğŸ’— Magenta Gradients**  | **Pattern Recognition**   | Light magenta â†’ Deep magenta | Abstraction and emergence               |
| **ğŸŸ¢ Green Gradients**    | **External Interface**    | Light green â†’ Forest green   | Environmental interaction               |

### Numbered Interaction Callouts

The main diagram includes **22 numbered interaction points** (â‘  through ã‰’) that trace the complete cognitive flow from perception through reasoning, learning, attention allocation, and action execution. These numbers enable precise reference to specific cognitive processes and their synergistic relationships.

### Visual Emphasis Specifications

- **Bold Borders (4px)**: AtomSpace as the central cognitive hub
- **Gradient Fills**: Dynamic state transitions and cognitive processes
- **Icons & Emojis**: Semantic enhancement for rapid visual parsing
- **Layered Subgraphs**: Hierarchical organization of cognitive functions
- **Recursive Containers**: Grouped interconnected nodes showing synergistic relationships

---

## Hypergraph-Encoded Cognitive Patterns & Implementation Guidance

### Scheme-Style Pseudocode for Cognitive Schematics

The following pseudocode illustrates how CogPrime's recursive cognitive schematics (Câ†’Pâ†’G) can be represented within the AtomSpace hypergraph structure:

```scheme
;; Cognitive Schematic: Context â†’ Procedure â†’ Goal
(ImplicationLink (stv 0.85 0.92)  ; High confidence in this schematic
  (AndLink
    (StateLink (ConceptNode "Eva") (ConceptNode "human-present"))
    (StateLink (ConceptNode "Room") (ConceptNode "occupied")))
  (SequentialLink
    (ExecutionLink (SchemaNode "initiate-greeting") (VariableNode "$human"))
    (ExecutionLink (SchemaNode "maintain-eye-contact") (VariableNode "$human"))
    (ExecutionLink (SchemaNode "assess-human-mood") (VariableNode "$human"))))

;; Goal Achievement Structure
(EvaluationLink (stv 0.78 0.89)
  (PredicateNode "goal-achieved")
  (ListLink
    (ConceptNode "human-engagement")
    (ConceptNode "positive-interaction")))

;; ECAN Attention Allocation
(AtomSpace
  (set-sti! (ConceptNode "human-present") 800)     ; High short-term importance
  (set-lti! (ConceptNode "greeting-behavior") 600) ; Moderate long-term importance
  (set-av! (SchemaNode "initiate-greeting") (av 750 550))) ; Attention values
```

### Distributed Cognition Framework Implementation

CogPrime's architecture embodies **distributed cognition principles** through:

#### 1. Concurrent MindAgent Architecture

```scheme
;; Multiple MindAgents operating simultaneously on shared AtomSpace
(define mind-agents
  (list
    (create-pln-agent (attention-allocation ecan-instance))
    (create-moses-agent (goal-context goal-system))
    (create-ecan-agent (spreading-parameters '((sti-decay 0.1) (importance-threshold 50))))
    (create-simulation-agent (episodic-buffer temporal-links))
    (create-pattern-mining-agent (cognitive-equation-params))))

;; Concurrent access patterns with conflict resolution
(atomspace-concurrent-access
  (agents mind-agents)
  (conflict-resolution-strategy 'attention-weighted)
  (synchronization-protocol 'hypergraph-locks))
```

#### 2. Attention-Weighted Hypergraph Dynamics

```scheme
;; ECAN spreading dynamics across hypergraph structure
(define (spread-attention source-atom spreading-factor)
  (for-each
    (lambda (linked-atom)
      (let ((current-sti (get-sti linked-atom))
            (spread-amount (* (get-sti source-atom) spreading-factor)))
        (set-sti! linked-atom (+ current-sti spread-amount))))
    (get-incoming-links source-atom)))

;; Attention-guided processing priority
(define (process-by-attention atomspace threshold)
  (filter (lambda (atom) (> (get-sti atom) threshold))
          (get-all-atoms atomspace)))
```

#### 3. Emergent Pattern Recognition through Hypergraph Mining

```scheme
;; Pattern mining for cognitive equation implementation
(define (mine-cognitive-patterns atomspace pattern-threshold)
  (let ((frequent-subgraphs (find-frequent-subgraphs atomspace pattern-threshold)))
    (map (lambda (pattern)
           (create-pattern-atom pattern (calculate-pattern-strength pattern)))
         frequent-subgraphs)))

;; Embody discovered patterns as new atoms
(define (embody-pattern pattern strength)
  (let ((pattern-node (ConceptNode (generate-pattern-name pattern))))
    (set-tv! pattern-node (stv strength 0.85))
    (create-pattern-links pattern pattern-node)
    pattern-node))
```

### Neural-Symbolic Integration Mechanisms

#### Truth Value Propagation in Logical Networks

```scheme
;; PLN inference with uncertainty handling
(define (pln-inference premise conclusion)
  (let ((premise-tv (get-tv premise))
        (conclusion-tv (get-tv conclusion))
        (inference-rule 'modus-ponens))
    (calculate-inference-result premise-tv conclusion-tv inference-rule)))

;; Integration with MOSES procedural knowledge
(define (integrate-logic-procedure logical-atom procedural-schema)
  (ImplicationLink (stv 0.8 0.9)
    logical-atom
    (ExecutionLink procedural-schema (VariableNode "$context"))))
```

#### Evolutionary Procedure Optimization

```scheme
;; MOSES evolution with PLN-guided fitness
(define (moses-evolution population goal-atom)
  (let ((fitness-function (create-pln-guided-fitness goal-atom)))
    (evolve-population population
                      fitness-function
                      (genetic-operators '(crossover mutation selection))
                      (attention-bias (get-sti goal-atom)))))
```

### Cognitive Transcendence Through Recursive Enhancement

The CogPrime architecture achieves **cognitive transcendence** through recursive pathways that enhance each component's capabilities:

1. **Recursive Self-Improvement**: Each cognitive process improves its own performance through meta-cognitive feedback
2. **Cross-Modal Enhancement**: Different cognitive modalities strengthen each other through synergistic interaction
3. **Emergent Complexity**: Simple hypergraph operations give rise to sophisticated cognitive behaviors
4. **Adaptive Abstraction**: The system continuously creates new levels of conceptual understanding

### Optimization Guidelines for Cognitive Synergy

#### Memory Access Patterns

- **Locality-Aware Processing**: Leverage hypergraph connectivity for efficient access patterns
- **Attention-Guided Caching**: Cache high-STI atoms for faster access by multiple MindAgents
- **Hierarchical Knowledge Organization**: Structure atoms in conceptual hierarchies for efficient reasoning

#### Computational Resource Management

- **ECAN-Driven Scheduling**: Use attention values to prioritize computational resources
- **Parallel Processing**: Exploit concurrent MindAgent architecture for scalable performance
- **Adaptive Resource Allocation**: Dynamically adjust processing priorities based on cognitive load

#### Cognitive Load Balancing

- **Bottleneck Detection**: Monitor inter-process communication for performance optimization
- **Synergy Maximization**: Encourage beneficial cross-process interactions while minimizing overhead
- **Emergent Behavior Cultivation**: Create conditions that foster beneficial emergent cognitive patterns

This hypergraph-encoded cognitive architecture enables seamless integration of symbolic reasoning, evolutionary learning, attention allocation, and embodied interactionâ€”achieving the neural-symbolic synergy essential for artificial general intelligence.

---

_This enhanced architecture diagram implements recursive documentation patterns designed for cognitive synergy, distributed comprehension, and continual evolution of architectural transparency. The visual and conceptual enhancements preserve all original technical accuracy while elevating the document as a hypergraph-encoded cognitive map for advanced AGI understanding._
